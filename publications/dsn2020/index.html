<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Hugo 0.149.0"><meta name=author content="Subho Sankar Banerjee"><meta name=description content="ML-driven Malware that Targets AV Safety"><meta property="og:url" content="https://ssbanerje.github.io/publications/dsn2020/"><meta property="og:site_name" content="Subho Sankar Banerjee"><meta property="og:title" content="ML-driven Malware that Targets AV Safety"><meta property="og:description" content="Ensuring the safety of autonomous vehicles (AVs) is critical for their mass deployment and public adoption. However, security attacks that violate safety constraints and cause accidents are a major deterrent to achieving public trust in AVs which hinders a vendors’ ability to deploy the AVs. Creating a security hazard that results in a serious safety compromise (for example, an accident) is compelling from an attacker’s perspective. In this paper, we introduce an attack model, a method to deploy the attack in the form of a smart malware, and experimental evaluation of its impact on production grade autonomous driving software. We find that determining the time interval during which to launch the attack is critically important for causing safety hazards (such as collision) with a high degree of success. For example, the smart malware caused 32× more forced emergency braking compared to random attacks, and accidents in 52.6% of the driving simulations."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="publications"><meta property="article:published_time" content="2020-06-30T00:00:00+00:00"><meta property="article:modified_time" content="2020-06-30T00:00:00+00:00"><meta itemprop=name content="ML-driven Malware that Targets AV Safety"><meta itemprop=description content="Ensuring the safety of autonomous vehicles (AVs) is critical for their mass deployment and public adoption. However, security attacks that violate safety constraints and cause accidents are a major deterrent to achieving public trust in AVs which hinders a vendors’ ability to deploy the AVs. Creating a security hazard that results in a serious safety compromise (for example, an accident) is compelling from an attacker’s perspective. In this paper, we introduce an attack model, a method to deploy the attack in the form of a smart malware, and experimental evaluation of its impact on production grade autonomous driving software. We find that determining the time interval during which to launch the attack is critically important for causing safety hazards (such as collision) with a high degree of success. For example, the smart malware caused 32× more forced emergency braking compared to random attacks, and accidents in 52.6% of the driving simulations."><meta itemprop=datePublished content="2020-06-30T00:00:00+00:00"><meta itemprop=dateModified content="2020-06-30T00:00:00+00:00"><meta itemprop=wordCount content="151"><meta name=twitter:card content="summary"><meta name=twitter:title content="ML-driven Malware that Targets AV Safety"><meta name=twitter:description content="Ensuring the safety of autonomous vehicles (AVs) is critical for their mass deployment and public adoption. However, security attacks that violate safety constraints and cause accidents are a major deterrent to achieving public trust in AVs which hinders a vendors’ ability to deploy the AVs. Creating a security hazard that results in a serious safety compromise (for example, an accident) is compelling from an attacker’s perspective. In this paper, we introduce an attack model, a method to deploy the attack in the form of a smart malware, and experimental evaluation of its impact on production grade autonomous driving software. We find that determining the time interval during which to launch the attack is critically important for causing safety hazards (such as collision) with a high degree of success. For example, the smart malware caused 32× more forced emergency braking compared to random attacks, and accidents in 52.6% of the driving simulations."><meta name=theme-color content="#141f33"><title>ML-Driven Malware That Targets AV Safety | Subho Sankar Banerjee</title><link rel=canonical href=/publications/dsn2020/><link rel=icon href=/img/favicon.ico><link rel="shortcut icon" href=/img/favicon.ico><link rel=apple-touch-icon href=/img/favicon.ico><link rel=stylesheet href=/css/style.min.a5fd5df6db3eafce9b1c5f5fabeadc25c3d64c8798012ac48a13c5fb32861ce7.css><link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,400;0,700;1,400;1,700&amp;family=Inconsolata:ital,wght@0,400;0,700;1,400;1,700&amp;family=Eczar:ital,wght@0,400;0,700;1,400;1,700&display=swap" crossorigin=anonymous type=text/css rel=stylesheet><link href=https://unpkg.com/academicons@1.8.6/css/academicons.min.css crossorigin=anonymous type=text/css rel=stylesheet rel=preload as=style onload='this.onload=null,this.rel="stylesheet"'><link href=https://unpkg.com/components-font-awesome@5.9.0/css/all.min.css crossorigin=anonymous type=text/css rel=stylesheet rel=preload as=style onload='this.onload=null,this.rel="stylesheet"'></head><body><div class="columns is-gapless is-marginless"><div class="column is-one-quarter-tablet is-narrow-desktop" id=sidebar><div class=padded-sidebar><section class=section><figure class="image container" style=margin-bottom:2rem><img class=is-rounded src=/img/me_sq.png alt=Avatar></figure><div class="sidebar-content has-text-centered"><h1 class="title is-1"><a href=/>Subho Sankar Banerjee</a></h1><p class="has-text-white-ter has-text-centered">Software Engineer @ Google</p><ul class="icon-list is-clearfix"><li><a href=mailto:remove_this_if_human_ssbaner2@illinois.edu><i class="fas fa-envelope-open fa-fw"></i></a></li><li><a href="https://illinois.edu/map/view?buildingId=148"><i class="fas fa-map-marker-alt fa-fw"></i></a></li><li><a href="https://scholar.google.com/citations?user=jvV04p3aXgMC"><i class="ai ai-google-scholar fa-fw"></i></a></li><li><a href="https://dblp.uni-trier.de/pers/hd/b/Banerjee:Subho_S="><i class="ai ai-dblp fa-fw"></i></a></li><li><a href=https://www.linkedin.com/in/ssbanerjee><i class="fab fa-linkedin fa-fw"></i></a></li><li><a href=https://github.com/ssbanerje><i class="fab fa-github fa-fw"></i></a></li></ul></div></section></div></div><div class=column><div id=content class=has-text-justified><section class=section><nav class=breadcrumb aria-label=breadcrumbs><ul><li><a href=/><span class="icon is-small"><i class="fas fa-home" aria-hidden=true></i></span><span>Home</span></a></li><li><a href=/publications/>Publications</a></li><li class=is-active><a href=# aria-current=page>This Page</a></li></ul></nav></section><section class=section><div class=has-text-left><h1 class="title is-1 no-border">ML-driven Malware that Targets AV Safety</h1><h3 class="title is-3">Saurabh Jha, Shengkun Cui, Subho S. Banerjee, James Cyriac, Timothy Tsai, Zbigniew T. Kalbarczyk, and Ravishankar K. Iyer</h3><h3 class="title is-3 has-text-grey"><i>DSN 2020</i></h3></div><br><hr><ul class="single-paper-links is-size-3"><li><a href=https://ieeexplore.ieee.org/document/9153375 target=_blank rel=noreferrer rel=noopener><i class="ai ai-ieee" aria-hidden=true></i>&nbsp;DOI</a></li><li><a href=https://arxiv.org/abs/2004.13004 target=_blank rel=noreferrer rel=noopener><i class="ai ai-arxiv" aria-hidden=true></i>&nbsp;arXiv</a></li><li><a href=/publications/dsn2020/Paper.pdf target=_blank rel=noreferrer rel=noopener><i class="far fa-file-pdf" aria-hidden=true></i>&nbsp;Paper</a></li></ul></section><section class=section><h2 class="title is-2">Abstract</h2><div class=content><p>Ensuring the safety of autonomous vehicles (AVs) is critical for their mass deployment and public
adoption. However, security attacks that violate safety constraints and cause accidents are a
major deterrent to achieving public trust in AVs which hinders a vendors&rsquo; ability to deploy the AVs.
Creating a security hazard that results in a serious safety compromise (for example, an accident) is
compelling from an attacker&rsquo;s perspective. In this paper, we introduce an attack model, a method to
deploy the attack in the form of a smart malware, and experimental evaluation of its impact on
production grade autonomous driving software. We find that determining the time interval during
which to launch the attack is critically important for causing safety hazards (such as collision)
with a high degree of success. For example, the smart malware caused 32× more forced emergency
braking compared to random attacks, and accidents in 52.6% of the driving simulations.</p></div></section><section class=section style=margin-bottom:1rem><h2 class="title is-2">Citation
<a href=/publications/dsn2020/ref.bib style=font-size:80%><i class="far fa-arrow-alt-circle-down"></i></a></h2><div class=highlight><pre tabindex=0 style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bibtex data-lang=bibtex><span style=display:flex><span><span style=color:#0a8;font-weight:700>@INPROCEEDINGS</span>{<span style=color:#99f>Jha2020</span>,
</span></span><span style=display:flex><span>  <span style=color:#309>author</span>=<span style=color:#c30>{S. {Jha} and S. {Cui} and S. S. {Banerjee} and J. {Cyriac} and T. {Tsai} and Z. {Kalbarczyk} and R. K. {Iyer}}</span>,
</span></span><span style=display:flex><span>  <span style=color:#309>booktitle</span>=<span style=color:#c30>{2020 50th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN)}</span>,
</span></span><span style=display:flex><span>  <span style=color:#309>title</span>=<span style=color:#c30>{ML-Driven Malware that Targets AV Safety}</span>,
</span></span><span style=display:flex><span>  <span style=color:#309>year</span>=<span style=color:#c30>{2020}</span>,
</span></span><span style=display:flex><span>  <span style=color:#309>volume</span>=<span style=color:#c30>{}</span>,
</span></span><span style=display:flex><span>  <span style=color:#309>number</span>=<span style=color:#c30>{}</span>,
</span></span><span style=display:flex><span>  <span style=color:#309>pages</span>=<span style=color:#c30>{113-124}</span>,
</span></span><span style=display:flex><span>} 
</span></span></code></pre></div></section><section class=section style=margin-bottom:1rem><h2 class="title is-2">Related Projects</h2><ul class=bulleted-list><li><a href=/projects/av/>Autonomous Vehicle Resilience</a></li></ul></section></div><footer class=footer><div class="content has-text-left has-text-dark"><ul><li><span class="icon has-text-info"><i class="fas fa-heading fa-fw"></i></span> Powered by <a href=https://www.gohugo.io>Hugo</a></li><li><span class="icon has-text-link"><i class="fas fa-pencil-alt fa-fw"></i></span> Last updated 08/28/2025</li><li><a href=https://ssbanerje.github.io/index.xml><span class="icon has-text-orange"><i class="fas fa-rss fa-fw"></i></span> Feed</a></li></ul></div></footer></div><div class="column is-1 is-hidden-touch" id=right></div></div><script src=https://unpkg.com/quicklink@2.0.0/dist/quicklink.umd.js integrity=sha384-0nZ9FdSjDH2+tAS8yrmxpBHVMFs28rYR4bDVPFEoQqfzvezs/7OW7ebNI7CrWAg7 crossorigin=anonymous async></script><script>window.addEventListener("load",()=>{quicklink.listen({ignores:[e=>e.includes(".pdf"),e=>e.includes(".bib"),(e,t)=>t.hasAttribute("noprefetch")]})})</script></body></html>