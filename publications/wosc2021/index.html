<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Hugo 0.149.0"><meta name=author content="Subho Sankar Banerjee"><meta name=description content="Is Function-as-a-Service a Good Fit for Latency-Critical Services?"><meta property="og:url" content="https://ssbanerje.github.io/publications/wosc2021/"><meta property="og:site_name" content="Subho Sankar Banerjee"><meta property="og:title" content="Is Function-as-a-Service a Good Fit for Latency-Critical Services?"><meta property="og:description" content="Function-as-a-Service (FaaS) is becoming an increasingly popular cloud-deployment paradigm for serverless computing that frees application developers from managing the infrastructure. At the same time, it allows cloud providers to assert control in workload consolidation, i.e., co-locating multiple containers on the same server, thereby achieving higher server utilization, often at the cost of higher end-to-end function request latency. Interestingly, a key aspect of serverless latency management has not been well studied: the trade-off between application developers’ latency goals and the FaaS providers’ utilization goals. This paper presents a multi-faceted, measurement-driven study of latency variation in serverless platforms that elucidates this trade-off space. We obtained production measurements by executing FaaS benchmarks on IBM Cloud and a private cloud to study the impact of workload consolidation, queuing delay, and cold starts on the end-to-end function request latency. We draw several conclusions. For example, increasing a container’s allocated memory limit from 128 MB to 256 MB reduces the tail latency by 2x but has 1.75x higher power consumption and 59% lower CPU utilization."><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="publications"><meta property="article:published_time" content="2021-12-06T00:00:00+00:00"><meta property="article:modified_time" content="2021-12-06T00:00:00+00:00"><meta itemprop=name content="Is Function-as-a-Service a Good Fit for Latency-Critical Services?"><meta itemprop=description content="Function-as-a-Service (FaaS) is becoming an increasingly popular cloud-deployment paradigm for serverless computing that frees application developers from managing the infrastructure. At the same time, it allows cloud providers to assert control in workload consolidation, i.e., co-locating multiple containers on the same server, thereby achieving higher server utilization, often at the cost of higher end-to-end function request latency. Interestingly, a key aspect of serverless latency management has not been well studied: the trade-off between application developers’ latency goals and the FaaS providers’ utilization goals. This paper presents a multi-faceted, measurement-driven study of latency variation in serverless platforms that elucidates this trade-off space. We obtained production measurements by executing FaaS benchmarks on IBM Cloud and a private cloud to study the impact of workload consolidation, queuing delay, and cold starts on the end-to-end function request latency. We draw several conclusions. For example, increasing a container’s allocated memory limit from 128 MB to 256 MB reduces the tail latency by 2x but has 1.75x higher power consumption and 59% lower CPU utilization."><meta itemprop=datePublished content="2021-12-06T00:00:00+00:00"><meta itemprop=dateModified content="2021-12-06T00:00:00+00:00"><meta itemprop=wordCount content="169"><meta name=twitter:card content="summary"><meta name=twitter:title content="Is Function-as-a-Service a Good Fit for Latency-Critical Services?"><meta name=twitter:description content="Function-as-a-Service (FaaS) is becoming an increasingly popular cloud-deployment paradigm for serverless computing that frees application developers from managing the infrastructure. At the same time, it allows cloud providers to assert control in workload consolidation, i.e., co-locating multiple containers on the same server, thereby achieving higher server utilization, often at the cost of higher end-to-end function request latency. Interestingly, a key aspect of serverless latency management has not been well studied: the trade-off between application developers’ latency goals and the FaaS providers’ utilization goals. This paper presents a multi-faceted, measurement-driven study of latency variation in serverless platforms that elucidates this trade-off space. We obtained production measurements by executing FaaS benchmarks on IBM Cloud and a private cloud to study the impact of workload consolidation, queuing delay, and cold starts on the end-to-end function request latency. We draw several conclusions. For example, increasing a container’s allocated memory limit from 128 MB to 256 MB reduces the tail latency by 2x but has 1.75x higher power consumption and 59% lower CPU utilization."><meta name=theme-color content="#141f33"><title>Is Function-as-a-Service a Good Fit for Latency-Critical Services? | Subho Sankar Banerjee</title><link rel=canonical href=/publications/wosc2021/><link rel=icon href=/img/favicon.ico><link rel="shortcut icon" href=/img/favicon.ico><link rel=apple-touch-icon href=/img/favicon.ico><link rel=stylesheet href=/css/style.min.a5fd5df6db3eafce9b1c5f5fabeadc25c3d64c8798012ac48a13c5fb32861ce7.css><link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,400;0,700;1,400;1,700&amp;family=Inconsolata:ital,wght@0,400;0,700;1,400;1,700&amp;family=Eczar:ital,wght@0,400;0,700;1,400;1,700&display=swap" crossorigin=anonymous type=text/css rel=stylesheet><link href=https://unpkg.com/academicons@1.8.6/css/academicons.min.css crossorigin=anonymous type=text/css rel=stylesheet rel=preload as=style onload='this.onload=null,this.rel="stylesheet"'><link href=https://unpkg.com/components-font-awesome@5.9.0/css/all.min.css crossorigin=anonymous type=text/css rel=stylesheet rel=preload as=style onload='this.onload=null,this.rel="stylesheet"'></head><body><div class="columns is-gapless is-marginless"><div class="column is-one-quarter-tablet is-narrow-desktop" id=sidebar><div class=padded-sidebar><section class=section><figure class="image container" style=margin-bottom:2rem><img class=is-rounded src=/img/me_sq.png alt=Avatar></figure><div class="sidebar-content has-text-centered"><h1 class="title is-1"><a href=/>Subho Sankar Banerjee</a></h1><p class="has-text-white-ter has-text-centered">Software Engineer @ Google</p><ul class="icon-list is-clearfix"><li><a href=mailto:remove_this_if_human_ssbaner2@illinois.edu><i class="fas fa-envelope-open fa-fw"></i></a></li><li><a href="https://illinois.edu/map/view?buildingId=148"><i class="fas fa-map-marker-alt fa-fw"></i></a></li><li><a href="https://scholar.google.com/citations?user=jvV04p3aXgMC"><i class="ai ai-google-scholar fa-fw"></i></a></li><li><a href="https://dblp.uni-trier.de/pers/hd/b/Banerjee:Subho_S="><i class="ai ai-dblp fa-fw"></i></a></li><li><a href=https://www.linkedin.com/in/ssbanerjee><i class="fab fa-linkedin fa-fw"></i></a></li><li><a href=https://github.com/ssbanerje><i class="fab fa-github fa-fw"></i></a></li></ul></div></section></div></div><div class=column><div id=content class=has-text-justified><section class=section><nav class=breadcrumb aria-label=breadcrumbs><ul><li><a href=/><span class="icon is-small"><i class="fas fa-home" aria-hidden=true></i></span><span>Home</span></a></li><li><a href=/publications/>Publications</a></li><li class=is-active><a href=# aria-current=page>This Page</a></li></ul></nav></section><section class=section><div class=has-text-left><h1 class="title is-1 no-border">Is Function-as-a-Service a Good Fit for Latency-Critical Services?</h1><h3 class="title is-3">Haoran Qiu, Saurabh Jha, Subho S. Banerjee, Archit Patke, Chen Wang, Hubertus Franke, Zbigniew T. Kalbarczyk, and Ravishankar K. Iyer</h3><h3 class="title is-3 has-text-grey"><i>WoSC 2021 (Colocated with Middleware 2021)</i></h3></div><br><hr><ul class="single-paper-links is-size-3"></ul></section><section class=section><h2 class="title is-2">Abstract</h2><div class=content><p>Function-as-a-Service (FaaS) is becoming an increasingly popular cloud-deployment paradigm for serverless computing that
frees application developers from managing the infrastructure. At the same time, it allows cloud providers to assert
control in workload consolidation, i.e., co-locating multiple containers on the same server, thereby achieving higher
server utilization, often at the cost of higher end-to-end function request latency. Interestingly, a key aspect of
serverless latency management has not been well studied: the trade-off between application developers’ latency goals and
the FaaS providers’ utilization goals. This paper presents a multi-faceted, measurement-driven study of latency
variation in serverless platforms that elucidates this trade-off space. We obtained production measurements by executing
FaaS benchmarks on IBM Cloud and a private cloud to study the impact of workload consolidation, queuing delay, and cold
starts on the end-to-end function request latency. We draw several conclusions. For example, increasing a container’s
allocated memory limit from 128 MB to 256 MB reduces the tail latency by 2x but has 1.75x higher power consumption and
59% lower CPU utilization.</p></div></section><section class=section style=margin-bottom:1rem><h2 class="title is-2">Related Projects</h2><ul class=bulleted-list><li><a href=/projects/learnedsystems/>Intelligence Augmented Compter Systems</a></li></ul></section></div><footer class=footer><div class="content has-text-left has-text-dark"><ul><li><span class="icon has-text-info"><i class="fas fa-heading fa-fw"></i></span> Powered by <a href=https://www.gohugo.io>Hugo</a></li><li><span class="icon has-text-link"><i class="fas fa-pencil-alt fa-fw"></i></span> Last updated 08/28/2025</li><li><a href=https://ssbanerje.github.io/index.xml><span class="icon has-text-orange"><i class="fas fa-rss fa-fw"></i></span> Feed</a></li></ul></div></footer></div><div class="column is-1 is-hidden-touch" id=right></div></div><script src=https://unpkg.com/quicklink@2.0.0/dist/quicklink.umd.js integrity=sha384-0nZ9FdSjDH2+tAS8yrmxpBHVMFs28rYR4bDVPFEoQqfzvezs/7OW7ebNI7CrWAg7 crossorigin=anonymous async></script><script>window.addEventListener("load",()=>{quicklink.listen({ignores:[e=>e.includes(".pdf"),e=>e.includes(".bib"),(e,t)=>t.hasAttribute("noprefetch")]})})</script></body></html>